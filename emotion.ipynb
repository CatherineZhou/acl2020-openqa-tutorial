{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19c0c84d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-09-02T09:57:07.778110Z",
     "iopub.status.busy": "2022-09-02T09:57:07.777538Z",
     "iopub.status.idle": "2022-09-02T09:57:07.800606Z",
     "shell.execute_reply": "2022-09-02T09:57:07.799447Z"
    },
    "papermill": {
     "duration": 0.036936,
     "end_time": "2022-09-02T09:57:07.804423",
     "exception": false,
     "start_time": "2022-09-02T09:57:07.767487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/__notebook__.ipynb\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/working'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdae9e5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T09:57:07.824187Z",
     "iopub.status.busy": "2022-09-02T09:57:07.822220Z",
     "iopub.status.idle": "2022-09-02T09:57:07.833950Z",
     "shell.execute_reply": "2022-09-02T09:57:07.832277Z"
    },
    "papermill": {
     "duration": 0.023673,
     "end_time": "2022-09-02T09:57:07.836903",
     "exception": false,
     "start_time": "2022-09-02T09:57:07.813230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'/kaggle/working'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfc0b020",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T09:57:07.850453Z",
     "iopub.status.busy": "2022-09-02T09:57:07.849760Z",
     "iopub.status.idle": "2022-09-02T09:57:17.730981Z",
     "shell.execute_reply": "2022-09-02T09:57:17.724269Z"
    },
    "papermill": {
     "duration": 9.891209,
     "end_time": "2022-09-02T09:57:17.733995",
     "exception": false,
     "start_time": "2022-09-02T09:57:07.842786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcatherine1015\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20220902_095711-yr1y5bwv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/catherine1015/emotion_model/runs/yr1y5bwv\" target=\"_blank\">astral-night-5</a></strong> to <a href=\"https://wandb.ai/catherine1015/emotion_model\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/catherine1015/emotion_model/runs/yr1y5bwv?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f94b427ff90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# secret_value_0 = user_secrets.get_secret(\"kate\")\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "os.system(\"wandb login 525037aaae74525566dca1246bce266cc1c1330b\")\n",
    "\n",
    "import wandb\n",
    "wandb.init(project=\"emotion_model\", entity=\"catherine1015\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc951cb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T09:57:17.773527Z",
     "iopub.status.busy": "2022-09-02T09:57:17.773141Z",
     "iopub.status.idle": "2022-09-02T09:57:17.798862Z",
     "shell.execute_reply": "2022-09-02T09:57:17.797936Z"
    },
    "papermill": {
     "duration": 0.048194,
     "end_time": "2022-09-02T09:57:17.801250",
     "exception": false,
     "start_time": "2022-09-02T09:57:17.753056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/kaggle/input/weibodata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c8472dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T09:57:17.831796Z",
     "iopub.status.busy": "2022-09-02T09:57:17.831104Z",
     "iopub.status.idle": "2022-09-02T09:59:11.774126Z",
     "shell.execute_reply": "2022-09-02T09:59:11.772844Z"
    },
    "papermill": {
     "duration": 113.960821,
     "end_time": "2022-09-02T09:59:11.776726",
     "exception": false,
     "start_time": "2022-09-02T09:57:17.815905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting harvesttext==0.8.1.4\r\n",
      "  Downloading harvesttext-0.8.1.4-py3-none-any.whl (1.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting loguru==0.5.3\r\n",
      "  Downloading loguru-0.5.3-py3-none-any.whl (57 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting numpy==1.19.2\r\n",
      "  Downloading numpy-1.19.2-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting pyhanlp==0.1.79\r\n",
      "  Downloading pyhanlp-0.1.79.tar.gz (136 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.8/136.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: scikit_learn==1.0.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (1.0.2)\r\n",
      "Collecting torch==1.9.0\r\n",
      "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.4/831.4 MB\u001b[0m \u001b[31m837.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting tqdm==4.50.2\r\n",
      "  Downloading tqdm-4.50.2-py2.py3-none-any.whl (70 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.9/70.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting transformers==4.15.0\r\n",
      "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting tensorboard==2.7.0\r\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from harvesttext==0.8.1.4->-r requirements.txt (line 1)) (3.5.3)\r\n",
      "Collecting opencc-python-reimplemented\r\n",
      "  Downloading opencc-python-reimplemented-0.1.6.tar.gz (484 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.6/484.6 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting rdflib\r\n",
      "  Downloading rdflib-6.2.0-py3-none-any.whl (500 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.3/500.3 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from harvesttext==0.8.1.4->-r requirements.txt (line 1)) (3.7)\r\n",
      "Collecting w3lib\r\n",
      "  Downloading w3lib-2.0.1-py3-none-any.whl (20 kB)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.7/site-packages (from harvesttext==0.8.1.4->-r requirements.txt (line 1)) (2.5)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from harvesttext==0.8.1.4->-r requirements.txt (line 1)) (1.7.3)\r\n",
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.7/site-packages (from harvesttext==0.8.1.4->-r requirements.txt (line 1)) (4.0.1)\r\n",
      "Collecting pypinyin\r\n",
      "  Downloading pypinyin-0.47.1-py2.py3-none-any.whl (1.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: jieba in /opt/conda/lib/python3.7/site-packages (from harvesttext==0.8.1.4->-r requirements.txt (line 1)) (0.42.1)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from harvesttext==0.8.1.4->-r requirements.txt (line 1)) (1.3.5)\r\n",
      "Requirement already satisfied: python-louvain in /opt/conda/lib/python3.7/site-packages (from harvesttext==0.8.1.4->-r requirements.txt (line 1)) (0.16)\r\n",
      "Collecting jpype1==0.7.0\r\n",
      "  Downloading JPype1-0.7.0-cp37-cp37m-manylinux2010_x86_64.whl (2.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting hanlp-downloader\r\n",
      "  Downloading hanlp_downloader-0.0.25.tar.gz (13 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn==1.0.2->-r requirements.txt (line 5)) (3.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn==1.0.2->-r requirements.txt (line 5)) (1.0.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.9.0->-r requirements.txt (line 6)) (4.3.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.15.0->-r requirements.txt (line 8)) (3.7.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.15.0->-r requirements.txt (line 8)) (6.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.15.0->-r requirements.txt (line 8)) (2.28.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.15.0->-r requirements.txt (line 8)) (4.12.0)\r\n",
      "Collecting tokenizers<0.11,>=0.10.1\r\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.15.0->-r requirements.txt (line 8)) (21.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.15.0->-r requirements.txt (line 8)) (2021.11.10)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.15.0->-r requirements.txt (line 8)) (0.8.1)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==4.15.0->-r requirements.txt (line 8)) (0.0.53)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.7.0->-r requirements.txt (line 9)) (0.4.6)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.7.0->-r requirements.txt (line 9)) (1.35.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.7.0->-r requirements.txt (line 9)) (0.6.1)\r\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.7.0->-r requirements.txt (line 9)) (3.19.4)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.7.0->-r requirements.txt (line 9)) (3.3.7)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.7.0->-r requirements.txt (line 9)) (2.2.2)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.7.0->-r requirements.txt (line 9)) (0.37.1)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.7.0->-r requirements.txt (line 9)) (59.8.0)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.7.0->-r requirements.txt (line 9)) (1.43.0)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.7.0->-r requirements.txt (line 9)) (1.8.1)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.7.0->-r requirements.txt (line 9)) (0.15.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py>=0.4->tensorboard==2.7.0->-r requirements.txt (line 9)) (1.15.0)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.7.0->-r requirements.txt (line 9)) (4.2.4)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.7.0->-r requirements.txt (line 9)) (4.8)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.7.0->-r requirements.txt (line 9)) (0.2.7)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.7.0->-r requirements.txt (line 9)) (1.3.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.15.0->-r requirements.txt (line 8)) (3.8.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers==4.15.0->-r requirements.txt (line 8)) (3.0.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.15.0->-r requirements.txt (line 8)) (3.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.15.0->-r requirements.txt (line 8)) (2022.6.15)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.15.0->-r requirements.txt (line 8)) (2.1.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.15.0->-r requirements.txt (line 8)) (1.26.12)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=0.11.15->tensorboard==2.7.0->-r requirements.txt (line 9)) (2.1.1)\r\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim->harvesttext==0.8.1.4->-r requirements.txt (line 1)) (5.2.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->harvesttext==0.8.1.4->-r requirements.txt (line 1)) (2.8.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->harvesttext==0.8.1.4->-r requirements.txt (line 1)) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->harvesttext==0.8.1.4->-r requirements.txt (line 1)) (4.33.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->harvesttext==0.8.1.4->-r requirements.txt (line 1)) (9.1.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->harvesttext==0.8.1.4->-r requirements.txt (line 1)) (1.4.3)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx->harvesttext==0.8.1.4->-r requirements.txt (line 1)) (5.1.1)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->harvesttext==0.8.1.4->-r requirements.txt (line 1)) (8.0.4)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->harvesttext==0.8.1.4->-r requirements.txt (line 1)) (2022.1)\r\n",
      "Collecting isodate\r\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.7.0->-r requirements.txt (line 9)) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.7.0->-r requirements.txt (line 9)) (3.2.0)\r\n",
      "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'pyhanlp' candidate (version 0.1.79 at https://files.pythonhosted.org/packages/a0/f0/0fd645f554491d7a969669a37aae6c0aaf7b197c154a064a3392680e0994/pyhanlp-0.1.79.tar.gz#sha256=ec9095eaa7e8a81c4783361e549fe643e758a0c78c8accd265d78478ec75b888 (from https://pypi.org/simple/pyhanlp/) (requires-python:<3.9))\r\n",
      "Reason for being yanked: Requires Python<=3.8\u001b[0m\u001b[33m\r\n",
      "\u001b[0mBuilding wheels for collected packages: pyhanlp, hanlp-downloader, opencc-python-reimplemented\r\n",
      "  Building wheel for pyhanlp (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyhanlp: filename=pyhanlp-0.1.79-py3-none-any.whl size=29804 sha256=85109396716ba125d1f45196b58d5251c763f5f0b57e1ba2590718ad80d60ca0\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/27/48/ad/61fea783778a3ea1bf4a62b7eab8f93842694cde7f9899e03b\r\n",
      "  Building wheel for hanlp-downloader (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for hanlp-downloader: filename=hanlp_downloader-0.0.25-py3-none-any.whl size=13776 sha256=0195434cbf8e5650818327f344a14e6f24d17ad7f692689a9afd57ba097dacc9\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/cb/a2/c3/61f7b80f5d56e5b19dd9cb50303f8f3b621662f035a281d197\r\n",
      "  Building wheel for opencc-python-reimplemented (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for opencc-python-reimplemented: filename=opencc_python_reimplemented-0.1.6-py2.py3-none-any.whl size=486152 sha256=e6d37a2e7efe4678e7e6b415ba9ccf73f145c1596210b1af0af1e8cbcb225008\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/4e/e2/60/d062d260be08788bb389521544a8fc173de9a9a78d6a593344\r\n",
      "Successfully built pyhanlp hanlp-downloader opencc-python-reimplemented\r\n",
      "Installing collected packages: tokenizers, opencc-python-reimplemented, jpype1, w3lib, tqdm, torch, pypinyin, numpy, loguru, isodate, rdflib, hanlp-downloader, pyhanlp, transformers, tensorboard, harvesttext\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.12.1\r\n",
      "    Uninstalling tokenizers-0.12.1:\r\n",
      "      Successfully uninstalled tokenizers-0.12.1\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.64.0\r\n",
      "    Uninstalling tqdm-4.64.0:\r\n",
      "      Successfully uninstalled tqdm-4.64.0\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 1.11.0\r\n",
      "    Uninstalling torch-1.11.0:\r\n",
      "      Successfully uninstalled torch-1.11.0\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.21.6\r\n",
      "    Uninstalling numpy-1.21.6:\r\n",
      "      Successfully uninstalled numpy-1.21.6\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.20.1\r\n",
      "    Uninstalling transformers-4.20.1:\r\n",
      "      Successfully uninstalled transformers-4.20.1\r\n",
      "  Attempting uninstall: tensorboard\r\n",
      "    Found existing installation: tensorboard 2.10.0\r\n",
      "    Uninstalling tensorboard-2.10.0:\r\n",
      "      Successfully uninstalled tensorboard-2.10.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\r\n",
      "dask-cudf 21.10.1 requires cupy-cuda114, which is not installed.\r\n",
      "beatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\r\n",
      "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.2 which is incompatible.\r\n",
      "thinc 8.0.17 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.3.0 which is incompatible.\r\n",
      "tfx-bsl 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires h5py~=3.1.0, but you have h5py 3.7.0 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires tensorboard<2.7,>=2.6.0, but you have tensorboard 2.7.0 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires typing-extensions<3.11,>=3.7, but you have typing-extensions 4.3.0 which is incompatible.\r\n",
      "tensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\r\n",
      "tensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 2.6.4 which is incompatible.\r\n",
      "spacy 3.3.1 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.3.0 which is incompatible.\r\n",
      "pytorch-lightning 1.7.2 requires tensorboard>=2.9.1, but you have tensorboard 2.7.0 which is incompatible.\r\n",
      "pytorch-lightning 1.7.2 requires tqdm>=4.57.0, but you have tqdm 4.50.2 which is incompatible.\r\n",
      "pdpbox 0.2.1 requires matplotlib==3.1.1, but you have matplotlib 3.5.3 which is incompatible.\r\n",
      "pandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible.\r\n",
      "nnabla 1.29.0 requires numpy>=1.20.0, but you have numpy 1.19.2 which is incompatible.\r\n",
      "kaggle-environments 1.9.11 requires numpy>=1.19.5, but you have numpy 1.19.2 which is incompatible.\r\n",
      "jax 0.3.16 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.\r\n",
      "flax 0.6.0 requires rich~=11.1, but you have rich 12.1.0 which is incompatible.\r\n",
      "featuretools 1.11.1 requires numpy>=1.21.0, but you have numpy 1.19.2 which is incompatible.\r\n",
      "datasets 2.1.0 requires tqdm>=4.62.1, but you have tqdm 4.50.2 which is incompatible.\r\n",
      "dask-cudf 21.10.1 requires dask==2021.09.1, but you have dask 2022.2.0 which is incompatible.\r\n",
      "dask-cudf 21.10.1 requires distributed==2021.09.1, but you have distributed 2022.2.0 which is incompatible.\r\n",
      "cmdstanpy 1.0.4 requires numpy>=1.21, but you have numpy 1.19.2 which is incompatible.\r\n",
      "apache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\r\n",
      "allennlp 2.10.0 requires numpy>=1.21.4, but you have numpy 1.19.2 which is incompatible.\r\n",
      "allennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\r\n",
      "allennlp 2.10.0 requires torch<1.12.0,>=1.10.0, but you have torch 1.9.0 which is incompatible.\r\n",
      "allennlp 2.10.0 requires tqdm>=4.62, but you have tqdm 4.50.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed hanlp-downloader-0.0.25 harvesttext-0.8.1.4 isodate-0.6.1 jpype1-0.7.0 loguru-0.5.3 numpy-1.19.2 opencc-python-reimplemented-0.1.6 pyhanlp-0.1.79 pypinyin-0.47.1 rdflib-6.2.0 tensorboard-2.7.0 tokenizers-0.10.3 torch-1.9.0 tqdm-4.50.2 transformers-4.15.0 w3lib-2.0.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce0fdee1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T09:59:11.848081Z",
     "iopub.status.busy": "2022-09-02T09:59:11.847330Z",
     "iopub.status.idle": "2022-09-02T09:59:17.636294Z",
     "shell.execute_reply": "2022-09-02T09:59:17.635080Z"
    },
    "papermill": {
     "duration": 5.827354,
     "end_time": "2022-09-02T09:59:17.638819",
     "exception": false,
     "start_time": "2022-09-02T09:59:11.811465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import shutil\n",
    "import argparse\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "from torch.cuda import amp\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e89530bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T09:59:17.713435Z",
     "iopub.status.busy": "2022-09-02T09:59:17.712597Z",
     "iopub.status.idle": "2022-09-02T09:59:17.785337Z",
     "shell.execute_reply": "2022-09-02T09:59:17.784202Z"
    },
    "papermill": {
     "duration": 0.114402,
     "end_time": "2022-09-02T09:59:17.788270",
     "exception": false,
     "start_time": "2022-09-02T09:59:17.673868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34071c91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T09:59:17.861255Z",
     "iopub.status.busy": "2022-09-02T09:59:17.860371Z",
     "iopub.status.idle": "2022-09-02T09:59:17.873152Z",
     "shell.execute_reply": "2022-09-02T09:59:17.872259Z"
    },
    "papermill": {
     "duration": 0.052076,
     "end_time": "2022-09-02T09:59:17.876067",
     "exception": false,
     "start_time": "2022-09-02T09:59:17.823991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WBDataset(Dataset):\n",
    "    def __init__(self, path, tokenizer='bert-base-chinese'):\n",
    "        self.data_list = self._read_file(path)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer)\n",
    "        self.label = {'happy': 0, 'angry': 1, 'sad': 2, 'fear': 3, 'surprise': 4, 'neutral': 5}\n",
    "\n",
    "    def _read_file(self, path):\n",
    "        with open(path, 'r') as f:\n",
    "            data_list = json.load(f)\n",
    "        return data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data_list[index]\n",
    "        content = data['content']\n",
    "        label = self.label[data['label']]\n",
    "        token = self.tokenizer(content, padding='max_length', truncation=True, max_length=140)\n",
    "        input_ids = token['input_ids']\n",
    "        token_type_ids = token['token_type_ids']\n",
    "        attention_mask = token['attention_mask']\n",
    "        return input_ids, token_type_ids, attention_mask, label\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        input_ids, token_type_ids, attention_mask, label = list(zip(*batch))\n",
    "        input_ids = torch.tensor(input_ids)\n",
    "        token_type_ids = torch.tensor(token_type_ids)\n",
    "        attention_mask = torch.tensor(attention_mask)\n",
    "        label = torch.tensor(label)\n",
    "        return input_ids, token_type_ids, attention_mask, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b19633f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T09:59:17.950209Z",
     "iopub.status.busy": "2022-09-02T09:59:17.949810Z",
     "iopub.status.idle": "2022-09-02T09:59:17.980923Z",
     "shell.execute_reply": "2022-09-02T09:59:17.979964Z"
    },
    "papermill": {
     "duration": 0.071389,
     "end_time": "2022-09-02T09:59:17.984782",
     "exception": false,
     "start_time": "2022-09-02T09:59:17.913393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, train_dataloader, model, lr, epochs, output_dir, val_dataloader=None, save_model_iter=5):\n",
    "        self.device = torch.device(device) #'cuda:0'\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.n_batch = len(train_dataloader)\n",
    "        self.model = model.to(self.device)\n",
    "        self.lr = lr\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr)\n",
    "        self.num_training_steps = self.n_batch * epochs\n",
    "        self.scheduler = get_linear_schedule_with_warmup(optimizer=self.optimizer,\n",
    "                                                         num_training_steps=self.num_training_steps,\n",
    "                                                         num_warmup_steps=self.n_batch)\n",
    "        self.scaler = amp.GradScaler(enabled=True)\n",
    "        self.epochs = epochs\n",
    "        self.start_epoch = 0\n",
    "        self.global_step = 0\n",
    "        self.save_model_iter = save_model_iter\n",
    "        self.output_dir = output_dir\n",
    "        self._init_logger()\n",
    "\n",
    "        self.writer = SummaryWriter(os.path.join(self.output_dir, 'tensorboard'))\n",
    "        self.metrics = {'val_loss': 0, 'val_acc': 0, 'val_f1_score': 0}\n",
    "\n",
    "    def _init_logger(self):\n",
    "        log_file_name = 'train_{time}.log'\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "        log_path = os.path.join(self.output_dir, log_file_name)\n",
    "        logger.add(log_path, rotation='1 week', retention='30 days', enqueue=True)\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        pbar = tqdm(enumerate(self.train_dataloader), total=self.n_batch)\n",
    "        train_loss = AverageMeter('Loss', ':6.3f')\n",
    "        acc = AverageMeter('acc', ':6.3f')\n",
    "        f1 = AverageMeter('f1_score', ':6.3f')\n",
    "\n",
    "        for index, (input_ids, token_type_ids, attention_mask, label) in pbar:\n",
    "            self.global_step += 1\n",
    "            output = model(input_ids=input_ids.to(self.device), attention_mask=attention_mask.to(self.device),\n",
    "                           labels=label.to(self.device))\n",
    "            loss = output.loss\n",
    "            logits = output.logits\n",
    "\n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.step(self.optimizer)  # optimizer.step\n",
    "            self.scaler.update()\n",
    "            self.optimizer.zero_grad()\n",
    "            self.scheduler.step()\n",
    "\n",
    "            preds = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
    "            train_f1_score = f1_score(y_true=label.cpu().numpy(), y_pred=preds, average='macro')\n",
    "            train_acc = accuracy_score(y_true=label.cpu().numpy(), y_pred=preds)\n",
    "            train_loss.update(loss.detach().cpu().numpy().tolist())\n",
    "            acc.update(train_acc)\n",
    "            f1.update(train_f1_score)\n",
    "            pbar.set_description(f'{train_loss.avg: .3f}  {acc.avg: .3f}  {f1.avg: .3f}')\n",
    "            pbar.set_postfix({'epoch': str(epoch) + '/' + str(self.epochs),\n",
    "                              'lr': self.optimizer.state_dict()['param_groups'][0]['lr']})\n",
    "\n",
    "            self.writer.add_scalar('Train/loss', train_loss.avg, self.global_step)\n",
    "            self.writer.add_scalar('Train/acc', acc.avg, self.global_step)\n",
    "            self.writer.add_scalar('Train/f1_score', f1.avg, self.global_step)\n",
    "            self.writer.add_scalar('Train/lr', self.optimizer.state_dict()['param_groups'][0]['lr'],\n",
    "                                   self.global_step)\n",
    "\n",
    "        logger.info(f'{train_loss.avg: .3f}  {acc.avg: .3f}  {f1.avg: .3f}')\n",
    "\n",
    "    def on_epoch_finish(self, epoch):\n",
    "        save_best = False\n",
    "        metric = None\n",
    "        if self.val_dataloader is not None:\n",
    "            with torch.no_grad():\n",
    "                val_loss, val_acc, val_f1_score = self._val()\n",
    "            self.writer.add_scalar('Val/loss', val_loss, epoch)\n",
    "            self.writer.add_scalar('Val/acc', val_acc, epoch)\n",
    "            self.writer.add_scalar('Val/f1_score', val_f1_score, epoch)\n",
    "            metric = {'val_loss': val_loss, 'val_acc': val_acc, 'val_f1_score': val_f1_score}\n",
    "            logger.info(f'complete {epoch} epochs, val result: {metric}')\n",
    "            print('----val_f1_score, val_f1_score',val_f1_score, self.metrics['val_f1_score'] )\n",
    "            if val_f1_score > self.metrics['val_f1_score']:\n",
    "                save_best = True\n",
    "                print('-------save_best', save_best)\n",
    "                self.metrics = {'val_loss': val_loss, 'val_acc': val_acc, 'val_f1_score': val_f1_score}\n",
    "\n",
    "        if save_best:\n",
    "            self._save_checkpoint(epoch, metric, save_best)\n",
    "\n",
    "        elif epoch % self.save_model_iter == 0:\n",
    "            self._save_checkpoint(epoch, metric)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def _save_checkpoint(self, epoch, metric, save_best=False):\n",
    "\n",
    "        state_dict = self.model.state_dict()\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'metric': metric,\n",
    "            'state_dict': state_dict,\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "            'scheduler': self.scheduler.state_dict(),\n",
    "        }\n",
    "\n",
    "        name = f'{epoch}.pt'\n",
    "        path = os.path.join(self.output_dir, name)\n",
    "        torch.save(state, path, _use_new_zipfile_serialization=False)\n",
    "        if save_best:\n",
    "            shutil.copy(path, os.path.join(self.output_dir, 'best.pt'))\n",
    "            logger.info(f'Saving current best: {path}')\n",
    "        else:\n",
    "            logger.info(f'Saving checkpoint: {path}')\n",
    "\n",
    "    def train(self):\n",
    "        logger.info('===============================START===============================')\n",
    "        for epoch in range(self.start_epoch + 1, self.epochs + 1):\n",
    "            print('\\n loss    acc    f1_score')\n",
    "            self.train_epoch(epoch)\n",
    "            self.on_epoch_finish(epoch)\n",
    "        logger.info(f'complete the training, best result: {self.metrics}')\n",
    "        logger.info('===============================END===============================')\n",
    "\n",
    "    def _val(self):\n",
    "        self.model.eval()\n",
    "        pbar = tqdm(enumerate(self.val_dataloader), total=len(self.val_dataloader))\n",
    "\n",
    "        preds = []\n",
    "        labels = []\n",
    "        losses = []\n",
    "        for index, (input_ids, token_type_ids, attention_mask, label) in pbar:\n",
    "            output = self.model(input_ids=input_ids.to(self.device), attention_mask=attention_mask.to(self.device),\n",
    "                                labels=label.to(self.device))\n",
    "\n",
    "            loss = output.loss\n",
    "            logits = output.logits\n",
    "            losses.append(loss.detach().cpu().numpy().tolist())\n",
    "            preds.extend(np.argmax(logits.detach().cpu().numpy(), axis=1).tolist())\n",
    "            labels.extend(label.cpu().numpy().tolist())\n",
    "        val_f1_score = f1_score(y_true=np.array(labels), y_pred=np.array(preds), average='macro')\n",
    "        val_acc = accuracy_score(y_true=np.array(labels), y_pred=np.array(preds))\n",
    "        val_loss = np.array(losses).mean()\n",
    "        return val_loss, val_acc, val_f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9c6943",
   "metadata": {
    "papermill": {
     "duration": 0.033853,
     "end_time": "2022-09-02T09:59:18.056444",
     "exception": false,
     "start_time": "2022-09-02T09:59:18.022591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8e1cdbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T09:59:18.127320Z",
     "iopub.status.busy": "2022-09-02T09:59:18.126962Z",
     "iopub.status.idle": "2022-09-02T09:59:18.139450Z",
     "shell.execute_reply": "2022-09-02T09:59:18.136961Z"
    },
    "papermill": {
     "duration": 0.051432,
     "end_time": "2022-09-02T09:59:18.142342",
     "exception": false,
     "start_time": "2022-09-02T09:59:18.090910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Bert fine-tune on SMP2020-EWECT Dataset')\n",
    "    parser.add_argument('--model_name', default='bert-base-chinese', type=str,help='huggingface transformer model name')\n",
    "    parser.add_argument('--num_labels', default=6, type=int, help='fine-tune num labels')\n",
    "    parser.add_argument('--train_data_path', default='/kaggle/input/weibodata1/clean/usual_train.txt', type=str, help='train data path')\n",
    "    parser.add_argument('--val_data_path', default='/kaggle/input/weibodata1/clean/usual_eval_labeled.txt', type=str,help='train data path')\n",
    "    parser.add_argument('--batch_size', default=64, type=int, help='train and validation batch size')\n",
    "    parser.add_argument('--dataloader_num_workors', default=8, type=int, help='pytorch dataloader num workers')\n",
    "    parser.add_argument('--lr', default=1e-5, type=float, help='train learning rate')\n",
    "    parser.add_argument('--epochs', default=30, type=int, help='train epochs')\n",
    "    parser.add_argument('--output_dir', default='/kaggle/working/', type=str, help='save dir')\n",
    "    parser.add_argument('--save_model_iter', default=5, type=int, help='save model num epochs on training')\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a08887ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T09:59:18.214451Z",
     "iopub.status.busy": "2022-09-02T09:59:18.213783Z",
     "iopub.status.idle": "2022-09-02T09:59:18.222214Z",
     "shell.execute_reply": "2022-09-02T09:59:18.221158Z"
    },
    "papermill": {
     "duration": 0.047226,
     "end_time": "2022-09-02T09:59:18.225915",
     "exception": false,
     "start_time": "2022-09-02T09:59:18.178689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---args Namespace(batch_size=64, dataloader_num_workors=8, epochs=30, lr=1e-05, model_name='bert-base-chinese', num_labels=6, output_dir='/kaggle/working/', save_model_iter=5, train_data_path='/kaggle/input/weibodata1/clean/usual_train.txt', val_data_path='/kaggle/input/weibodata1/clean/usual_eval_labeled.txt')\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "print('---args', args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a726d094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T09:59:18.298017Z",
     "iopub.status.busy": "2022-09-02T09:59:18.297632Z",
     "iopub.status.idle": "2022-09-02T09:59:39.128460Z",
     "shell.execute_reply": "2022-09-02T09:59:39.127562Z"
    },
    "papermill": {
     "duration": 20.868422,
     "end_time": "2022-09-02T09:59:39.130713",
     "exception": false,
     "start_time": "2022-09-02T09:59:18.262291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9ada29e4eb416baaa27b0e97f3d82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=624.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344f7b5763144f308821dcf68b7b352b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=411577189.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(args.model_name, num_labels=args.num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06ca299d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T09:59:39.205799Z",
     "iopub.status.busy": "2022-09-02T09:59:39.205442Z",
     "iopub.status.idle": "2022-09-02T09:59:44.605699Z",
     "shell.execute_reply": "2022-09-02T09:59:44.603932Z"
    },
    "papermill": {
     "duration": 5.438347,
     "end_time": "2022-09-02T09:59:44.608096",
     "exception": false,
     "start_time": "2022-09-02T09:59:39.169749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3d9ad34e76444e87d8b77b19d88e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d99b8815f5424dab2a74e98a4ac8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=109540.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165000cfdc9c4548883b4d0a3171c649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=268943.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "#print(model)\n",
    "train_dataset = WBDataset(args.train_data_path, args.model_name)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "                              num_workers=args.dataloader_num_workors,\n",
    "                              collate_fn=WBDataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f29ddb23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T09:59:44.686920Z",
     "iopub.status.busy": "2022-09-02T09:59:44.686536Z",
     "iopub.status.idle": "2022-09-02T12:59:55.024366Z",
     "shell.execute_reply": "2022-09-02T12:59:55.023209Z"
    },
    "papermill": {
     "duration": 10810.377339,
     "end_time": "2022-09-02T12:59:55.027117",
     "exception": false,
     "start_time": "2022-09-02T09:59:44.649778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 09:59:51.341 | INFO     | __main__:train:116 - ===============================START===============================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 1.172   0.565   0.440: 100%|██████████| 434/434 [05:49<00:00,  1.24it/s, epoch=1/30, lr=1e-5]\n",
      "2022-09-02 10:05:41.669 | INFO     | __main__:train_epoch:68 -  1.172   0.565   0.440\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.63it/s]\n",
      "2022-09-02 10:05:50.876 | INFO     | __main__:on_epoch_finish:80 - complete 1 epochs, val result: {'val_loss': 0.661243581213057, 'val_acc': 0.771657486229344, 'val_f1_score': 0.7368500026869432}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7368500026869432 0\n",
      "-------save_best True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 10:05:54.664 | INFO     | __main__:_save_checkpoint:111 - Saving current best: /kaggle/working/1.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.613   0.786   0.733: 100%|██████████| 434/434 [05:49<00:00,  1.24it/s, epoch=2/30, lr=9.66e-6]\n",
      "2022-09-02 10:11:44.959 | INFO     | __main__:train_epoch:68 -  0.613   0.786   0.733\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.71it/s]\n",
      "2022-09-02 10:11:53.999 | INFO     | __main__:on_epoch_finish:80 - complete 2 epochs, val result: {'val_loss': 0.6026068404316902, 'val_acc': 0.7926890335503255, 'val_f1_score': 0.7687895832953949}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7687895832953949 0.7368500026869432\n",
      "-------save_best True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 10:11:58.936 | INFO     | __main__:_save_checkpoint:111 - Saving current best: /kaggle/working/2.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.492   0.830   0.784: 100%|██████████| 434/434 [05:49<00:00,  1.24it/s, epoch=3/30, lr=9.31e-6]\n",
      "2022-09-02 10:17:49.028 | INFO     | __main__:train_epoch:68 -  0.492   0.830   0.784\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.62it/s]\n",
      "2022-09-02 10:17:58.282 | INFO     | __main__:on_epoch_finish:80 - complete 3 epochs, val result: {'val_loss': 0.6148992525413632, 'val_acc': 0.7941912869303956, 'val_f1_score': 0.7651954079572786}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7651954079572786 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.394   0.866   0.826: 100%|██████████| 434/434 [05:49<00:00,  1.24it/s, epoch=4/30, lr=8.97e-6]\n",
      "2022-09-02 10:23:48.399 | INFO     | __main__:train_epoch:68 -  0.394   0.866   0.826\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.68it/s]\n",
      "2022-09-02 10:23:57.529 | INFO     | __main__:on_epoch_finish:80 - complete 4 epochs, val result: {'val_loss': 0.6419242266565561, 'val_acc': 0.7781672508763144, 'val_f1_score': 0.7439812112949006}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7439812112949006 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.308   0.897   0.862: 100%|██████████| 434/434 [05:49<00:00,  1.24it/s, epoch=5/30, lr=8.62e-6]\n",
      "2022-09-02 10:29:47.668 | INFO     | __main__:train_epoch:68 -  0.308   0.897   0.862\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.65it/s]\n",
      "2022-09-02 10:29:56.998 | INFO     | __main__:on_epoch_finish:80 - complete 5 epochs, val result: {'val_loss': 0.7209157506003976, 'val_acc': 0.7771657486229344, 'val_f1_score': 0.7458114881379854}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7458114881379854 0.7687895832953949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 10:29:58.550 | INFO     | __main__:_save_checkpoint:113 - Saving checkpoint: /kaggle/working/5.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.235   0.922   0.893: 100%|██████████| 434/434 [05:50<00:00,  1.24it/s, epoch=6/30, lr=8.28e-6]\n",
      "2022-09-02 10:35:49.203 | INFO     | __main__:train_epoch:68 -  0.235   0.922   0.893\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.67it/s]\n",
      "2022-09-02 10:35:58.325 | INFO     | __main__:on_epoch_finish:80 - complete 6 epochs, val result: {'val_loss': 0.7555553438141942, 'val_acc': 0.7791687531296946, 'val_f1_score': 0.7482965753599516}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7482965753599516 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.176   0.944   0.920: 100%|██████████| 434/434 [05:49<00:00,  1.24it/s, epoch=7/30, lr=7.93e-6]\n",
      "2022-09-02 10:41:48.544 | INFO     | __main__:train_epoch:68 -  0.176   0.944   0.920\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.64it/s]\n",
      "2022-09-02 10:41:57.768 | INFO     | __main__:on_epoch_finish:80 - complete 7 epochs, val result: {'val_loss': 0.8456940203905106, 'val_acc': 0.7816725087631448, 'val_f1_score': 0.7508442963286294}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7508442963286294 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.134   0.959   0.937: 100%|██████████| 434/434 [05:49<00:00,  1.24it/s, epoch=8/30, lr=7.59e-6]\n",
      "2022-09-02 10:47:48.073 | INFO     | __main__:train_epoch:68 -  0.134   0.959   0.937\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.69it/s]\n",
      "2022-09-02 10:47:57.160 | INFO     | __main__:on_epoch_finish:80 - complete 8 epochs, val result: {'val_loss': 0.9210907416418195, 'val_acc': 0.7761642463695543, 'val_f1_score': 0.7427879445488292}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7427879445488292 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.105   0.968   0.951: 100%|██████████| 434/434 [05:49<00:00,  1.24it/s, epoch=9/30, lr=7.24e-6]\n",
      "2022-09-02 10:53:47.396 | INFO     | __main__:train_epoch:68 -  0.105   0.968   0.951\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.71it/s]\n",
      "2022-09-02 10:53:56.446 | INFO     | __main__:on_epoch_finish:80 - complete 9 epochs, val result: {'val_loss': 0.9435849575675093, 'val_acc': 0.7751627441161743, 'val_f1_score': 0.7440939437727786}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7440939437727786 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.089   0.974   0.962: 100%|██████████| 434/434 [05:50<00:00,  1.24it/s, epoch=10/30, lr=6.9e-6]\n",
      "2022-09-02 10:59:46.915 | INFO     | __main__:train_epoch:68 -  0.089   0.974   0.962\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.68it/s]\n",
      "2022-09-02 10:59:56.021 | INFO     | __main__:on_epoch_finish:80 - complete 10 epochs, val result: {'val_loss': 0.9642376694828272, 'val_acc': 0.7751627441161743, 'val_f1_score': 0.7413212439246876}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7413212439246876 0.7687895832953949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 10:59:57.711 | INFO     | __main__:_save_checkpoint:113 - Saving checkpoint: /kaggle/working/10.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.070   0.979   0.964: 100%|██████████| 434/434 [05:50<00:00,  1.24it/s, epoch=11/30, lr=6.55e-6]\n",
      "2022-09-02 11:05:48.342 | INFO     | __main__:train_epoch:68 -  0.070   0.979   0.964\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.68it/s]\n",
      "2022-09-02 11:05:57.436 | INFO     | __main__:on_epoch_finish:80 - complete 11 epochs, val result: {'val_loss': 1.0619122665375471, 'val_acc': 0.7741612418627942, 'val_f1_score': 0.739359525222191}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.739359525222191 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.059   0.983   0.972: 100%|██████████| 434/434 [05:49<00:00,  1.24it/s, epoch=12/30, lr=6.21e-6]\n",
      "2022-09-02 11:11:47.699 | INFO     | __main__:train_epoch:68 -  0.059   0.983   0.972\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.67it/s]\n",
      "2022-09-02 11:11:56.815 | INFO     | __main__:on_epoch_finish:80 - complete 12 epochs, val result: {'val_loss': 1.0600522145396098, 'val_acc': 0.771657486229344, 'val_f1_score': 0.7392350967242872}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7392350967242872 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.050   0.985   0.975: 100%|██████████| 434/434 [05:49<00:00,  1.24it/s, epoch=13/30, lr=5.86e-6]\n",
      "2022-09-02 11:17:47.238 | INFO     | __main__:train_epoch:68 -  0.050   0.985   0.975\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.66it/s]\n",
      "2022-09-02 11:17:56.708 | INFO     | __main__:on_epoch_finish:80 - complete 13 epochs, val result: {'val_loss': 1.146295465528965, 'val_acc': 0.7806710065097646, 'val_f1_score': 0.7479926734049792}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7479926734049792 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.046   0.986   0.978: 100%|██████████| 434/434 [05:50<00:00,  1.24it/s, epoch=14/30, lr=5.52e-6]\n",
      "2022-09-02 11:23:47.308 | INFO     | __main__:train_epoch:68 -  0.046   0.986   0.978\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.68it/s]\n",
      "2022-09-02 11:23:56.486 | INFO     | __main__:on_epoch_finish:80 - complete 14 epochs, val result: {'val_loss': 1.1183469854295254, 'val_acc': 0.7726589884827241, 'val_f1_score': 0.7397039543870504}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7397039543870504 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.040   0.987   0.980: 100%|██████████| 434/434 [05:50<00:00,  1.24it/s, epoch=15/30, lr=5.17e-6]\n",
      "2022-09-02 11:29:47.005 | INFO     | __main__:train_epoch:68 -  0.040   0.987   0.980\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.65it/s]\n",
      "2022-09-02 11:29:56.181 | INFO     | __main__:on_epoch_finish:80 - complete 15 epochs, val result: {'val_loss': 1.191891798749566, 'val_acc': 0.771156735102654, 'val_f1_score': 0.7361467170953219}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7361467170953219 0.7687895832953949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 11:29:57.721 | INFO     | __main__:_save_checkpoint:113 - Saving checkpoint: /kaggle/working/15.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.037   0.988   0.979: 100%|██████████| 434/434 [05:50<00:00,  1.24it/s, epoch=16/30, lr=4.83e-6]\n",
      "2022-09-02 11:35:48.269 | INFO     | __main__:train_epoch:68 -  0.037   0.988   0.979\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.67it/s]\n",
      "2022-09-02 11:35:57.401 | INFO     | __main__:on_epoch_finish:80 - complete 16 epochs, val result: {'val_loss': 1.1580770509317517, 'val_acc': 0.7746619929894842, 'val_f1_score': 0.7418628062567819}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7418628062567819 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.032   0.989   0.983: 100%|██████████| 434/434 [05:49<00:00,  1.24it/s, epoch=17/30, lr=4.48e-6]\n",
      "2022-09-02 11:41:47.591 | INFO     | __main__:train_epoch:68 -  0.032   0.989   0.983\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.65it/s]\n",
      "2022-09-02 11:41:56.776 | INFO     | __main__:on_epoch_finish:80 - complete 17 epochs, val result: {'val_loss': 1.221293892711401, 'val_acc': 0.7731597396094141, 'val_f1_score': 0.7390700891733499}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7390700891733499 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.027   0.991   0.985: 100%|██████████| 434/434 [05:49<00:00,  1.24it/s, epoch=18/30, lr=4.14e-6]\n",
      "2022-09-02 11:47:46.738 | INFO     | __main__:train_epoch:68 -  0.027   0.991   0.985\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.71it/s]\n",
      "2022-09-02 11:47:55.800 | INFO     | __main__:on_epoch_finish:80 - complete 18 epochs, val result: {'val_loss': 1.213932195212692, 'val_acc': 0.771657486229344, 'val_f1_score': 0.7416912260456455}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7416912260456455 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.027   0.991   0.984: 100%|██████████| 434/434 [05:49<00:00,  1.24it/s, epoch=19/30, lr=3.79e-6]\n",
      "2022-09-02 11:53:45.988 | INFO     | __main__:train_epoch:68 -  0.027   0.991   0.984\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.62it/s]\n",
      "2022-09-02 11:53:55.226 | INFO     | __main__:on_epoch_finish:80 - complete 19 epochs, val result: {'val_loss': 1.2393525019288063, 'val_acc': 0.7721582373560341, 'val_f1_score': 0.7391959526450291}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7391959526450291 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.024   0.992   0.986: 100%|██████████| 434/434 [05:49<00:00,  1.24it/s, epoch=20/30, lr=3.45e-6]\n",
      "2022-09-02 11:59:45.571 | INFO     | __main__:train_epoch:68 -  0.024   0.992   0.986\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.64it/s]\n",
      "2022-09-02 11:59:54.758 | INFO     | __main__:on_epoch_finish:80 - complete 20 epochs, val result: {'val_loss': 1.2884177304804325, 'val_acc': 0.7786680020030045, 'val_f1_score': 0.7441974629459382}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7441974629459382 0.7687895832953949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 11:59:56.306 | INFO     | __main__:_save_checkpoint:113 - Saving checkpoint: /kaggle/working/20.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.023   0.993   0.987: 100%|██████████| 434/434 [05:50<00:00,  1.24it/s, epoch=21/30, lr=3.1e-6]\n",
      "2022-09-02 12:05:47.095 | INFO     | __main__:train_epoch:68 -  0.023   0.993   0.987\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.71it/s]\n",
      "2022-09-02 12:05:56.118 | INFO     | __main__:on_epoch_finish:80 - complete 21 epochs, val result: {'val_loss': 1.2757347114384174, 'val_acc': 0.7731597396094141, 'val_f1_score': 0.7390661205518182}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7390661205518182 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.022   0.992   0.988: 100%|██████████| 434/434 [05:49<00:00,  1.24it/s, epoch=22/30, lr=2.76e-6]\n",
      "2022-09-02 12:11:46.389 | INFO     | __main__:train_epoch:68 -  0.022   0.992   0.988\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.72it/s]\n",
      "2022-09-02 12:11:55.413 | INFO     | __main__:on_epoch_finish:80 - complete 22 epochs, val result: {'val_loss': 1.304086409509182, 'val_acc': 0.7696544817225839, 'val_f1_score': 0.7391126543657053}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7391126543657053 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.019   0.993   0.990: 100%|██████████| 434/434 [05:50<00:00,  1.24it/s, epoch=23/30, lr=2.41e-6]\n",
      "2022-09-02 12:17:45.975 | INFO     | __main__:train_epoch:68 -  0.019   0.993   0.990\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.71it/s]\n",
      "2022-09-02 12:17:55.043 | INFO     | __main__:on_epoch_finish:80 - complete 23 epochs, val result: {'val_loss': 1.333685602992773, 'val_acc': 0.7686529794692039, 'val_f1_score': 0.7352408528380754}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7352408528380754 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.018   0.993   0.987: 100%|██████████| 434/434 [05:49<00:00,  1.24it/s, epoch=24/30, lr=2.07e-6]\n",
      "2022-09-02 12:23:45.450 | INFO     | __main__:train_epoch:68 -  0.018   0.993   0.987\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.71it/s]\n",
      "2022-09-02 12:23:54.517 | INFO     | __main__:on_epoch_finish:80 - complete 24 epochs, val result: {'val_loss': 1.2993257795460522, 'val_acc': 0.7751627441161743, 'val_f1_score': 0.7428580788754952}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7428580788754952 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.017   0.994   0.988: 100%|██████████| 434/434 [05:50<00:00,  1.24it/s, epoch=25/30, lr=1.72e-6]\n",
      "2022-09-02 12:29:45.075 | INFO     | __main__:train_epoch:68 -  0.017   0.994   0.988\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.67it/s]\n",
      "2022-09-02 12:29:54.365 | INFO     | __main__:on_epoch_finish:80 - complete 25 epochs, val result: {'val_loss': 1.350060684606433, 'val_acc': 0.7731597396094141, 'val_f1_score': 0.7438411477425307}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7438411477425307 0.7687895832953949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 12:29:55.922 | INFO     | __main__:_save_checkpoint:113 - Saving checkpoint: /kaggle/working/25.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.017   0.993   0.989: 100%|██████████| 434/434 [05:49<00:00,  1.24it/s, epoch=26/30, lr=1.38e-6]\n",
      "2022-09-02 12:35:46.040 | INFO     | __main__:train_epoch:68 -  0.017   0.993   0.989\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.67it/s]\n",
      "2022-09-02 12:35:55.169 | INFO     | __main__:on_epoch_finish:80 - complete 26 epochs, val result: {'val_loss': 1.4135051537305117, 'val_acc': 0.7771657486229344, 'val_f1_score': 0.7458645611922003}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7458645611922003 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.014   0.994   0.990: 100%|██████████| 434/434 [05:49<00:00,  1.24it/s, epoch=27/30, lr=1.03e-6]\n",
      "2022-09-02 12:41:45.399 | INFO     | __main__:train_epoch:68 -  0.014   0.994   0.990\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.67it/s]\n",
      "2022-09-02 12:41:54.660 | INFO     | __main__:on_epoch_finish:80 - complete 27 epochs, val result: {'val_loss': 1.3448751978576183, 'val_acc': 0.7756634952428643, 'val_f1_score': 0.7426757749878993}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7426757749878993 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.014   0.995   0.990: 100%|██████████| 434/434 [05:49<00:00,  1.24it/s, epoch=28/30, lr=6.9e-7]\n",
      "2022-09-02 12:47:44.637 | INFO     | __main__:train_epoch:68 -  0.014   0.995   0.990\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.69it/s]\n",
      "2022-09-02 12:47:53.721 | INFO     | __main__:on_epoch_finish:80 - complete 28 epochs, val result: {'val_loss': 1.3619027771055698, 'val_acc': 0.7751627441161743, 'val_f1_score': 0.7410608451586596}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7410608451586596 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.012   0.996   0.992: 100%|██████████| 434/434 [05:50<00:00,  1.24it/s, epoch=29/30, lr=3.45e-7]\n",
      "2022-09-02 12:53:44.170 | INFO     | __main__:train_epoch:68 -  0.012   0.996   0.992\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.65it/s]\n",
      "2022-09-02 12:53:53.464 | INFO     | __main__:on_epoch_finish:80 - complete 29 epochs, val result: {'val_loss': 1.3466047029942274, 'val_acc': 0.7736604907361042, 'val_f1_score': 0.7404462685220438}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7404462685220438 0.7687895832953949\n",
      "\n",
      " loss    acc    f1_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      " 0.012   0.995   0.992: 100%|██████████| 434/434 [05:50<00:00,  1.24it/s, epoch=30/30, lr=0]\n",
      "2022-09-02 12:59:44.173 | INFO     | __main__:train_epoch:68 -  0.012   0.995   0.992\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 32/32 [00:08<00:00,  3.71it/s]\n",
      "2022-09-02 12:59:53.260 | INFO     | __main__:on_epoch_finish:80 - complete 30 epochs, val result: {'val_loss': 1.3572149854153395, 'val_acc': 0.7741612418627942, 'val_f1_score': 0.7422494731255415}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----val_f1_score, val_f1_score 0.7422494731255415 0.7687895832953949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 12:59:55.011 | INFO     | __main__:_save_checkpoint:113 - Saving checkpoint: /kaggle/working/30.pt\n",
      "2022-09-02 12:59:55.014 | INFO     | __main__:train:121 - complete the training, best result: {'val_loss': 0.6026068404316902, 'val_acc': 0.7926890335503255, 'val_f1_score': 0.7687895832953949}\n",
      "2022-09-02 12:59:55.016 | INFO     | __main__:train:122 - ===============================END===============================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----train finished\n"
     ]
    }
   ],
   "source": [
    "val_dataset = WBDataset(args.val_data_path, args.model_name)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "                            num_workers=args.dataloader_num_workors,\n",
    "                            collate_fn=WBDataset.collate_fn, drop_last=False)\n",
    "trainer = Trainer(train_dataloader=train_dataloader, model=model, lr=args.lr, epochs=args.epochs,\n",
    "                  output_dir=args.output_dir, save_model_iter=args.save_model_iter, val_dataloader=val_dataloader)\n",
    "trainer.train()\n",
    "\n",
    "print('-----train finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dc9164",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T08:47:31.604248Z",
     "iopub.status.busy": "2022-09-02T08:47:31.603553Z",
     "iopub.status.idle": "2022-09-02T08:47:31.635714Z",
     "shell.execute_reply": "2022-09-02T08:47:31.633437Z",
     "shell.execute_reply.started": "2022-09-02T08:47:31.604211Z"
    },
    "papermill": {
     "duration": 2.319355,
     "end_time": "2022-09-02T12:59:59.797381",
     "exception": false,
     "start_time": "2022-09-02T12:59:57.478026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10985.589753,
   "end_time": "2022-09-02T13:00:05.599512",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-02T09:57:00.009759",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0c98d841704f4abda1a36624735da1db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0ca4cfb1cbaf4cb082a1f6618e3681b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_65cec90309864c98a667c05978a26181",
       "placeholder": "​",
       "style": "IPY_MODEL_a02d20d3292d44e485a835a901c78e14",
       "value": "&lt;tqdm.auto.tqdm object at 0x7f93deacacd0&gt;"
      }
     },
     "0f17c051bbc9421a80ee4dcd13b958dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0f9c663e2b524c14a5b1ebeeb5f49781",
       "placeholder": "​",
       "style": "IPY_MODEL_e19f654cde704905956b367c86d12e87",
       "value": "&lt;tqdm.auto.tqdm object at 0x7f93ddd50b50&gt;"
      }
     },
     "0f9c663e2b524c14a5b1ebeeb5f49781": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1252bef461de4ea3b253a350d2cf74e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "165000cfdc9c4548883b4d0a3171c649": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8485333a54ec43009341b50e4c6f6fda",
        "IPY_MODEL_a4a81e9029854aa5a327122cdd0231ec",
        "IPY_MODEL_75158c948df94908a6f03ab4745cbbcd"
       ],
       "layout": "IPY_MODEL_2946c71cd7f74a839ad7bbbfc218fc82"
      }
     },
     "16ca351539e2409fa1dafedc5f1d757d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_31cbac80ee164ab3857899d724aad5d9",
       "max": 29.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_998becd34de74518b6800905bad185b7",
       "value": 29.0
      }
     },
     "1d34385ff7d64b489aa5cecd0e5daa25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2269a18c8e7a4a80a1be33efb477f90a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2946c71cd7f74a839ad7bbbfc218fc82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2d9ada29e4eb416baaa27b0e97f3d82f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ee22554b0a71434eaa14b700a9185a4e",
        "IPY_MODEL_7c1f3b79d2174a59b1407f93235fc95a",
        "IPY_MODEL_bd572ff85bb64d85a094dcc7eef53629"
       ],
       "layout": "IPY_MODEL_ebed41b64c4b4f73b7076b008f3e532c"
      }
     },
     "2f0a88a8cdb14c488f2168a8891baddc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3140f37ed83642108074e0158159e3bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a8609addebd64bf49ea0be7c6e5e2b55",
       "placeholder": "​",
       "style": "IPY_MODEL_958d9dba512345caa90a249522a0f0e6",
       "value": "&lt;tqdm.auto.tqdm object at 0x7f93ddd9b6d0&gt;"
      }
     },
     "31cbac80ee164ab3857899d724aad5d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "344f7b5763144f308821dcf68b7b352b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8fdc5b509fe64248b0c109dbb5af088b",
        "IPY_MODEL_d7300efd26444a4b97a403e92f819844",
        "IPY_MODEL_0ca4cfb1cbaf4cb082a1f6618e3681b8"
       ],
       "layout": "IPY_MODEL_2f0a88a8cdb14c488f2168a8891baddc"
      }
     },
     "362b82bc495a44ed8c16f9e14b507875": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3ad8464b95e840439bd423f10372f05f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5010d09cf0114dab9aa6c86c2a2621e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "53f318beaf824fe78c8d804042b62811": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "548dc1bb0bef4ff1a4ed97cc98690ed7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "64ccb7f1135742d98f22caa5a802623b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_96d13be2f6f24936a2947dd097431634",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_548dc1bb0bef4ff1a4ed97cc98690ed7",
       "value": 0.0
      }
     },
     "65cec90309864c98a667c05978a26181": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6f47fcc7ba9a42c4bc4685d8b5e72310": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5010d09cf0114dab9aa6c86c2a2621e7",
       "placeholder": "​",
       "style": "IPY_MODEL_dc31595318054eea9113577439e3e796",
       "value": ""
      }
     },
     "7191e83e38df479da3db18cdf8c2a1f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "72bb417a3faf4ea4b2a5ec5c2bfec46f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fb2b0389938943c58bd40ac90ea1763d",
       "max": 109540.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1d34385ff7d64b489aa5cecd0e5daa25",
       "value": 109540.0
      }
     },
     "7500b2768f8448cf88ff6b1977b68ad8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "75158c948df94908a6f03ab4745cbbcd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_df2aa2649dfa4826a316295dbb24963e",
       "placeholder": "​",
       "style": "IPY_MODEL_c5f044fcc9b7499b8fb1d8843faeab2b",
       "value": "&lt;tqdm.auto.tqdm object at 0x7f93dddcc050&gt;"
      }
     },
     "7c1f3b79d2174a59b1407f93235fc95a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bfbf865b16db4e99aa3f072cc8608544",
       "max": 624.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_99a5a670a3664f83b65bfaa54f928c93",
       "value": 624.0
      }
     },
     "801ccd9e3353456aad3942f758fa517d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8485333a54ec43009341b50e4c6f6fda": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_53f318beaf824fe78c8d804042b62811",
       "placeholder": "​",
       "style": "IPY_MODEL_c78a3c61c2074717b57ce37d08db1a15",
       "value": ""
      }
     },
     "8fdc5b509fe64248b0c109dbb5af088b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_da753f0a23ca4542bd56b4e2df2e6482",
       "placeholder": "​",
       "style": "IPY_MODEL_7500b2768f8448cf88ff6b1977b68ad8",
       "value": ""
      }
     },
     "958d9dba512345caa90a249522a0f0e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "96d13be2f6f24936a2947dd097431634": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "998becd34de74518b6800905bad185b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "99a5a670a3664f83b65bfaa54f928c93": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9efd4d83057d4a6994698f40c3ac6ea3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a02d20d3292d44e485a835a901c78e14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a3265cc1ea254879bb2f02b0b97c6f7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f13c8b5d55a74bf4b2439a8b6b23360e",
        "IPY_MODEL_64ccb7f1135742d98f22caa5a802623b"
       ],
       "layout": "IPY_MODEL_7191e83e38df479da3db18cdf8c2a1f6"
      }
     },
     "a4a81e9029854aa5a327122cdd0231ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b7d4ebac61f445afac4075b0e4ddcf0d",
       "max": 268943.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d5f6e2297ca648d4a95ad0e8f4003481",
       "value": 268943.0
      }
     },
     "a8609addebd64bf49ea0be7c6e5e2b55": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ab3d9ad34e76444e87d8b77b19d88e3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6f47fcc7ba9a42c4bc4685d8b5e72310",
        "IPY_MODEL_16ca351539e2409fa1dafedc5f1d757d",
        "IPY_MODEL_3140f37ed83642108074e0158159e3bc"
       ],
       "layout": "IPY_MODEL_362b82bc495a44ed8c16f9e14b507875"
      }
     },
     "b7903fe410564d618a16b1b9994a78aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b7d4ebac61f445afac4075b0e4ddcf0d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bd572ff85bb64d85a094dcc7eef53629": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2269a18c8e7a4a80a1be33efb477f90a",
       "placeholder": "​",
       "style": "IPY_MODEL_3ad8464b95e840439bd423f10372f05f",
       "value": "&lt;tqdm.auto.tqdm object at 0x7f93e78cea50&gt;"
      }
     },
     "bfbf865b16db4e99aa3f072cc8608544": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c07b64d0b4394df1a51842d2135008f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c5f044fcc9b7499b8fb1d8843faeab2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c78a3c61c2074717b57ce37d08db1a15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c7d99b8815f5424dab2a74e98a4ac8dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_db56c41995054cec9db0964bbe023f90",
        "IPY_MODEL_72bb417a3faf4ea4b2a5ec5c2bfec46f",
        "IPY_MODEL_0f17c051bbc9421a80ee4dcd13b958dc"
       ],
       "layout": "IPY_MODEL_801ccd9e3353456aad3942f758fa517d"
      }
     },
     "ca87d622d1ec4ffdb26a0e51217933b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d54e47af3d36401ca3112080f1efb873": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d5f6e2297ca648d4a95ad0e8f4003481": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d7300efd26444a4b97a403e92f819844": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1252bef461de4ea3b253a350d2cf74e7",
       "max": 411577189.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f038bfdd87d84ef288f3ecb09c571494",
       "value": 411577189.0
      }
     },
     "da753f0a23ca4542bd56b4e2df2e6482": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "db56c41995054cec9db0964bbe023f90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9efd4d83057d4a6994698f40c3ac6ea3",
       "placeholder": "​",
       "style": "IPY_MODEL_ca87d622d1ec4ffdb26a0e51217933b2",
       "value": ""
      }
     },
     "dc31595318054eea9113577439e3e796": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "df2aa2649dfa4826a316295dbb24963e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e19f654cde704905956b367c86d12e87": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ebed41b64c4b4f73b7076b008f3e532c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ee22554b0a71434eaa14b700a9185a4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0c98d841704f4abda1a36624735da1db",
       "placeholder": "​",
       "style": "IPY_MODEL_c07b64d0b4394df1a51842d2135008f9",
       "value": ""
      }
     },
     "f038bfdd87d84ef288f3ecb09c571494": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f13c8b5d55a74bf4b2439a8b6b23360e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d54e47af3d36401ca3112080f1efb873",
       "placeholder": "​",
       "style": "IPY_MODEL_b7903fe410564d618a16b1b9994a78aa",
       "value": ""
      }
     },
     "fb2b0389938943c58bd40ac90ea1763d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
